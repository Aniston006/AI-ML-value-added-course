{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "555a59aa-95b8-4248-8343-9388f52af8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f357a32-dd8c-47fb-a431-5967e0a089a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "057b4064-761b-4e49-9d9a-2672a37b778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\",\"rb\") as fp:\n",
    "    train_data=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1d34579d-9620-4fd2-b9ff-c00f084af1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt',\"rb\") as fp:\n",
    "    test_data=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23b4d2db-d704-4e71-b69e-8953b691c996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e7950459-e765-402d-b362-140e2aef343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e881dba1-1ec4-415c-a18a-a95b06f352e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary got the milk there . John moved to the bedroom .'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "89deec56-b0a1-4035-87a4-bd76387c92f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is John in the kitchen ?'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bc87615a-13b9-4fdb-ab3e-179cabf3daeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary got the milk there . John moved to the bedroom . Mary discarded the milk . John went to the garden .'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bbbed40e-227a-41a3-8757-8f07f7c231df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is John in the kitchen ?'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "be41be89-9ae4-4da6-a92c-9d84906b78af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n o'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f373089-0bc5-479f-b122-0e64a5948c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n o'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_data[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3797aa5c-5ea4-4fdd-8e92-8f6778ec40a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g o t'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_data[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c881b15e-eb21-4ee5-b809-f74d1b2be5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "91aaf830-c467-4dfa-8a6b-352fee016bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bae4ba82-bd56-4e27-8d11-f3e6470b7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=test_data+train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29cc3f37-fdac-40bb-9ecd-c676522cc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,question,answer in all_data:\n",
    "    vocab=vocab.union(set(story))\n",
    "    vocab=vocab.union(set(question))\n",
    "    \n",
    "    \n",
    "     \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "643a4eac-c866-4e8b-a3fb-e7f72b6c144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bdad8fd7-9881-444e-b343-47d17279ee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "58f3b4bf-2b0d-4f74-af82-e4ae9e3b1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len=len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "94c928b7-14eb-48b4-a98d-08e8ad158baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len=max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cbd9feb8-8a60-4a4c-ada5-c7070d20f48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3ce3d31b-2ca5-4966-bc78-368f07c63c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len=max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2f6e3bee-d049-4e34-9d68-c5539ec6cd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a07879be-4d58-4f73-96cf-77fb5319864a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "59134792-d510-4c15-8e93-72e63204eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "df2871cd-7b7a-42d2-8756-a9aab8c902d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(tokenizer.word_index)+1\n",
    "print(\"Vocab size:\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "10850b38-5772-4d0a-b3ba-542fc0fa62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2275c2f2-bfac-4cdc-becb-615ceab59a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\administrator\\anaconda3\\lib\\site-packages (3.13.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras) (2.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras) (2.3.5)\n",
      "Requirement already satisfied: rich in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras) (3.15.1)\n",
      "Requirement already satisfied: optree in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras) (0.19.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras) (0.5.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from optree->keras) (4.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from rich->keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9544303f-45c2-4484-804e-59ecf1ea8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d0e9f4c5-d758-4808-8d1e-42df2b7902c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=['Mary moved to the bathroom,Sandra journeyed to the bedroom.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2618d071-e0d9-40a5-a969-e6a0bb09a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6815014e-4db9-4622-adf6-9ba767fad584",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a71c4657-16a6-45df-8759-df8db1f85627",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8ca017a0-4c8c-4c36-a1c1-8ffd20c183ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d3b94601-fe14-4a43-b5ac-d37fbeb4c819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mary': 1,\n",
       " 'garden': 2,\n",
       " 'bathroom': 3,\n",
       " 'bedroom': 4,\n",
       " 'went': 5,\n",
       " 'left': 6,\n",
       " 'the': 7,\n",
       " 'no': 8,\n",
       " 'john': 9,\n",
       " 'in': 10,\n",
       " '.': 11,\n",
       " 'is': 12,\n",
       " 'daniel': 13,\n",
       " 'got': 14,\n",
       " 'journeyed': 15,\n",
       " 'to': 16,\n",
       " 'picked': 17,\n",
       " 'discarded': 18,\n",
       " 'there': 19,\n",
       " 'moved': 20,\n",
       " '?': 21,\n",
       " 'sandra': 22,\n",
       " 'kitchen': 23,\n",
       " 'put': 24,\n",
       " 'apple': 25,\n",
       " 'down': 26,\n",
       " 'football': 27,\n",
       " 'dropped': 28,\n",
       " 'yes': 29,\n",
       " 'office': 30,\n",
       " 'travelled': 31,\n",
       " 'took': 32,\n",
       " 'milk': 33,\n",
       " 'hallway': 34,\n",
       " 'back': 35,\n",
       " 'grabbed': 36,\n",
       " 'up': 37}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3ec2c4cc-4531-4d42-9c68-7db65d863347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text=[]\n",
    "train_question_text=[]\n",
    "train_answers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e35f241b-9859-4137-afc5-5d0ca7d65792",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "25ecb136-a5b9-4ddf-8c26-8848287787b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq=tokenizer.texts_to_sequences(train_story_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5488ddb3-7fd4-434b-9668-ddd326a1fcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4f81409a-8d28-4f57-b0f4-dbc29a115650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f7159062-79e9-49b2-98a1-e015e280f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data,word_index=tokenizer.word_index,max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    X=[]\n",
    "    Xq=[]\n",
    "    Y=[]\n",
    "    for story,query,answer in data:\n",
    "        if'<unk>' not in word_index:\n",
    "            word_index['<unk>']=len(word_index)+1\n",
    "        x=[word_index.get(word.lower(),word_index['<unk>']) for word in story]\n",
    "        xq=[word_index.get(word.lower(),word_index['<unk>']) for word in query]\n",
    "        y=np.zeros(len(word_index)+1)\n",
    "        y[word_index[answer]]=1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return (pad_sequences(X,maxlen=max_story_len),pad_sequences(Xq,maxlen=max_question_len),np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "855f573a-1292-4c93-b6c7-3ac0198c8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train,queries_train,answers_train=vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "593574ce-d669-4369-9859-bd7644341f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 156)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "69436d16-1003-4852-9a47-0bcff2c3643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 39)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "072976cf-9516-4f0e-99ca-421949df4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test,queries_test,answers_test=vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2c7351c0-70a0-43e8-a4e2-6ab657bec37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  7,  4, 11],\n",
       "       [ 0,  0,  0, ...,  7,  2, 11],\n",
       "       [ 0,  0,  0, ...,  7,  2, 11],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  7, 25, 11],\n",
       "       [ 0,  0,  0, ...,  7,  2, 11],\n",
       "       [ 0,  0,  0, ..., 25, 19, 11]], shape=(1000, 156), dtype=int32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "40cd8b39-52ee-45ae-9e8a-dac194279515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  9, 10,  7, 23, 21],\n",
       "       [12,  9, 10,  7, 23, 21],\n",
       "       [12,  9, 10,  7,  2, 21],\n",
       "       ...,\n",
       "       [12,  1, 10,  7,  4, 21],\n",
       "       [12, 22, 10,  7,  2, 21],\n",
       "       [12,  1, 10,  7,  2, 21]], shape=(1000, 6), dtype=int32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4317c739-7e29-4288-8609-1ed2ab37cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(1000, 39))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0d8a7955-8609-4db3-8aaa-24ed41cb39e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cd499200-9846-4970-8fa3-120a5a27feec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2d3659d7-7e12-4eef-b114-2c3ab3ea1376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "82ce0227-f5d6-4dca-8ec2-7fca7cbe7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input,Activation,Dense,Permute,Dropout\n",
    "from keras.layers import add,dot,concatenate\n",
    "from keras.layers import LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2dcacfec-79ee-4a9c-ba7c-4930718c278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence=Input((max_story_len,))\n",
    "question=Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9583b3fb-8501-4a4a-8f25-1a979225ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_m=Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d9b72a81-8f2b-42bb-a023-f23c800bc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_c=Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f0c1f36a-0869-4e50-85eb-28682c62a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder=Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "852c5891-282a-419f-8157-cdc60e043f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m=input_encoder_m(input_sequence)\n",
    "input_encoded_c=input_encoder_c(input_sequence)\n",
    "question_encoded=question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d4e25506-9d48-4e36-9b71-29b0aa978870",
   "metadata": {},
   "outputs": [],
   "source": [
    "match=dot([input_encoded_m,question_encoded],axes=(2,2))\n",
    "match=Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a5c972b-728e-462a-a56c-7d0ae165316b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e85a4d61-00fd-4cf9-ae37-6d4347db1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=add([match,input_encoded_c])\n",
    "response=Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9274487f-e5e1-488e-979d-8ebb0f87ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=concatenate([response,question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "73cf37fc-4cca-4157-93e4-0499065b7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=LSTM(32,return_sequences=False)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cfe98452-3f46-4aa2-82eb-d4e4a46b4e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 32), dtype=float32, sparse=False, ragged=False, name=keras_tensor_84>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d640eded-9995-4ec0-a957-45851535b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=Dropout(0.5)(answer)\n",
    "answer=Dense(vocab_size)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8e88fbe2-e3f5-4a71-a2b1-1d12b5934949",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=Activation('softmax')(answer)\n",
    "model=Model([input_sequence,question],answer)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e96cac06-e459-42c8-9d50-db1f34775e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ embedding_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ embedding_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ lstm_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_27 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_19 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │              \u001b[38;5;34m64\u001b[0m │ input_layer_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_20 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m64\u001b[0m │ input_layer_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │          \u001b[38;5;34m12,416\u001b[0m │ embedding_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │          \u001b[38;5;34m12,416\u001b[0m │ embedding_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_7 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ lstm_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                │           \u001b[38;5;34m2,600\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,560</span> (107.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,560\u001b[0m (107.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,560</span> (107.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,560\u001b[0m (107.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input,Dense,LSTM,Embedding,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "max_len_input=inputs_train.shape[1]\n",
    "max_len_query=queries_train.shape[1]\n",
    "input1=Input(shape=(max_len_input,))\n",
    "x1=Embedding(vocab_size,64)(input1)\n",
    "x1=LSTM(32)(x1)\n",
    "input2=Input(shape=(max_len_query,))\n",
    "x2=Embedding(vocab_size,64)(input2)\n",
    "x2=LSTM(32)(x2)\n",
    "merged=concatenate([x1,x2])\n",
    "output=Dense(40,activation='softmax')(merged)\n",
    "model=Model(inputs=[input1,input2],outputs=output)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cb63c669-7a27-40c2-a589-27540e35e9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 39), output.shape=(None, 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[174]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mqueries_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43manswers_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mqueries_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43manswers_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:1166\u001b[39m, in \u001b[36mcategorical_crossentropy\u001b[39m\u001b[34m(target, output, from_logits, axis)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target.shape, output.shape):\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 != e2:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1167\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1168\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1169\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1170\u001b[39m         )\n\u001b[32m   1172\u001b[39m output, from_logits = _get_logits(\n\u001b[32m   1173\u001b[39m     output, from_logits, \u001b[33m\"\u001b[39m\u001b[33mSoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1174\u001b[39m )\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[31mValueError\u001b[39m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 39), output.shape=(None, 40)"
     ]
    }
   ],
   "source": [
    "history=model.fit([inputs_train,queries_train],answers_train,batch_size=32,epochs=30,validation_data=([inputs_test,queries_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8e2324b6-991f-4f95-b082-ffab74e6db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab_size =\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d7b26fd5-a022-401e-8e10-59e787dc4fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIXED vocab_size = 38\n"
     ]
    }
   ],
   "source": [
    "vocab_size = int(\n",
    "    max(inputs_train.max(), queries_train.max())\n",
    ") + 1\n",
    "\n",
    "print(\"FIXED vocab_size =\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "828dba53-5399-4225-a225-531b12ac71e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │ input_layer_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │ input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ embedding_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ embedding_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ lstm_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_28 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_29 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_21 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │           \u001b[38;5;34m2,432\u001b[0m │ input_layer_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_22 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m2,432\u001b[0m │ input_layer_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │          \u001b[38;5;34m12,416\u001b[0m │ embedding_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │          \u001b[38;5;34m12,416\u001b[0m │ embedding_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_8 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ lstm_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ lstm_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                │           \u001b[38;5;34m2,600\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,296</span> (126.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,296\u001b[0m (126.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,296</span> (126.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,296\u001b[0m (126.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "max_len_input = inputs_train.shape[1]\n",
    "max_len_query = queries_train.shape[1]\n",
    "\n",
    "input1 = Input(shape=(max_len_input,))\n",
    "x1 = Embedding(input_dim=vocab_size, output_dim=64)(input1)\n",
    "x1 = LSTM(32)(x1)\n",
    "\n",
    "input2 = Input(shape=(max_len_query,))\n",
    "x2 = Embedding(input_dim=vocab_size, output_dim=64)(input2)\n",
    "x2 = LSTM(32)(x2)\n",
    "\n",
    "merged = concatenate([x1, x2])\n",
    "output = Dense(40, activation='softmax')(merged)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "27ef6a37-47de-4c83-8ea4-57552d056b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 39), output.shape=(None, 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[178]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswers_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswers_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:1166\u001b[39m, in \u001b[36mcategorical_crossentropy\u001b[39m\u001b[34m(target, output, from_logits, axis)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target.shape, output.shape):\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 != e2:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1167\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1168\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1169\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1170\u001b[39m         )\n\u001b[32m   1172\u001b[39m output, from_logits = _get_logits(\n\u001b[32m   1173\u001b[39m     output, from_logits, \u001b[33m\"\u001b[39m\u001b[33mSoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1174\u001b[39m )\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[31mValueError\u001b[39m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 39), output.shape=(None, 40)"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [inputs_train, queries_train],\n",
    "    answers_train,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_data=([inputs_test, queries_test], answers_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f34b08cd-7a23-4f68-a397-114e2deb0092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in labels = 39\n"
     ]
    }
   ],
   "source": [
    "num_classes = answers_train.shape[1]\n",
    "print(\"Number of classes in labels =\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "50491ef3-89b9-4832-a31f-b4dc9eaefe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(num_classes, activation='softmax')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d3b6bb6a-7b9a-4ca4-8d46-0f8eedf9cc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ embedding_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ embedding_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ lstm_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,535</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_30 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_31 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_23 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │           \u001b[38;5;34m2,432\u001b[0m │ input_layer_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_24 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m2,432\u001b[0m │ input_layer_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │          \u001b[38;5;34m12,416\u001b[0m │ embedding_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │          \u001b[38;5;34m12,416\u001b[0m │ embedding_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_9 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ lstm_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ lstm_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)                │           \u001b[38;5;34m2,535\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,231</span> (125.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,231\u001b[0m (125.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,231</span> (125.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,231\u001b[0m (125.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "vocab_size = int(max(inputs_train.max(), queries_train.max())) + 1\n",
    "\n",
    "max_len_input = inputs_train.shape[1]\n",
    "max_len_query = queries_train.shape[1]\n",
    "\n",
    "input1 = Input(shape=(max_len_input,))\n",
    "x1 = Embedding(input_dim=vocab_size, output_dim=64)(input1)\n",
    "x1 = LSTM(32)(x1)\n",
    "\n",
    "input2 = Input(shape=(max_len_query,))\n",
    "x2 = Embedding(input_dim=vocab_size, output_dim=64)(input2)\n",
    "x2 = LSTM(32)(x2)\n",
    "\n",
    "merged = concatenate([x1, x2])\n",
    "\n",
    "num_classes = answers_train.shape[1]\n",
    "output = Dense(num_classes, activation='softmax')(merged)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1b17f3b5-fbf3-4793-bcdf-2e0197370ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 65ms/step - accuracy: 0.5009 - loss: 0.8723 - val_accuracy: 0.4970 - val_loss: 0.6946\n",
      "Epoch 2/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.5065 - loss: 0.6956 - val_accuracy: 0.4970 - val_loss: 0.6952\n",
      "Epoch 3/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.5004 - loss: 0.6971 - val_accuracy: 0.5030 - val_loss: 0.6947\n",
      "Epoch 4/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.4949 - loss: 0.6968 - val_accuracy: 0.5030 - val_loss: 0.6984\n",
      "Epoch 5/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.5045 - loss: 0.6951 - val_accuracy: 0.4970 - val_loss: 0.6938\n",
      "Epoch 6/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.5045 - loss: 0.6965 - val_accuracy: 0.5030 - val_loss: 0.6959\n",
      "Epoch 7/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.5025 - loss: 0.6961 - val_accuracy: 0.5060 - val_loss: 0.6931\n",
      "Epoch 8/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.4931 - loss: 0.6969 - val_accuracy: 0.5120 - val_loss: 0.6929\n",
      "Epoch 9/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.5081 - loss: 0.6953 - val_accuracy: 0.5030 - val_loss: 0.6999\n",
      "Epoch 10/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.5071 - loss: 0.6959 - val_accuracy: 0.4990 - val_loss: 0.6926\n",
      "Epoch 11/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.5006 - loss: 0.6955 - val_accuracy: 0.5250 - val_loss: 0.6926\n",
      "Epoch 12/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.5047 - loss: 0.6953 - val_accuracy: 0.5150 - val_loss: 0.6931\n",
      "Epoch 13/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.5142 - loss: 0.6942 - val_accuracy: 0.5180 - val_loss: 0.6928\n",
      "Epoch 14/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.5086 - loss: 0.6950 - val_accuracy: 0.5150 - val_loss: 0.6935\n",
      "Epoch 15/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.5126 - loss: 0.6944 - val_accuracy: 0.4970 - val_loss: 0.6987\n",
      "Epoch 16/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.5034 - loss: 0.6953 - val_accuracy: 0.4970 - val_loss: 0.7094\n",
      "Epoch 17/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.5044 - loss: 0.6948 - val_accuracy: 0.5030 - val_loss: 0.6950\n",
      "Epoch 18/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.5147 - loss: 0.6945 - val_accuracy: 0.5180 - val_loss: 0.6925\n",
      "Epoch 19/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.5153 - loss: 0.6938 - val_accuracy: 0.5030 - val_loss: 0.6984\n",
      "Epoch 20/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.5102 - loss: 0.6943 - val_accuracy: 0.5150 - val_loss: 0.6944\n",
      "Epoch 21/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.5154 - loss: 0.6939 - val_accuracy: 0.5030 - val_loss: 0.6941\n",
      "Epoch 22/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.5115 - loss: 0.6939 - val_accuracy: 0.4990 - val_loss: 0.6948\n",
      "Epoch 23/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.5125 - loss: 0.6941 - val_accuracy: 0.5030 - val_loss: 0.6960\n",
      "Epoch 24/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.5028 - loss: 0.6965 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
      "Epoch 25/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.5019 - loss: 0.6942 - val_accuracy: 0.5390 - val_loss: 0.6925\n",
      "Epoch 26/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.5123 - loss: 0.6944 - val_accuracy: 0.5100 - val_loss: 0.6931\n",
      "Epoch 27/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.5118 - loss: 0.6944 - val_accuracy: 0.5250 - val_loss: 0.6923\n",
      "Epoch 28/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.5131 - loss: 0.6934 - val_accuracy: 0.5140 - val_loss: 0.6934\n",
      "Epoch 29/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.5132 - loss: 0.6942 - val_accuracy: 0.4860 - val_loss: 0.6929\n",
      "Epoch 30/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.5142 - loss: 0.6939 - val_accuracy: 0.5430 - val_loss: 0.6923\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [inputs_train, queries_train],\n",
    "    answers_train,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_data=([inputs_test, queries_test], answers_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e760e1de-d848-44b3-925b-d790b0cf98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='chatbot_120_epochs.keras'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3ac8d9c1-68f0-415e-a7ab-3693753ab799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results=model.predict(([inputs_test,queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5eb83f50-fea9-463f-a258-60a7e7431003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story=' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6e160ae2-b047-4b72-b9d4-cde826f32e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query=' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "67efd842-1c58-4038-ba99-638e963b2a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True test Answer from data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True test Answer from data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3e2071c0-8372-4f12-874d-dc192bcd94a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted answer is: no\n",
      "probability of certainity was:  0.510423\n"
     ]
    }
   ],
   "source": [
    "val_max=np.argmax(pred_results[0])\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val==val_max:\n",
    "        k=key\n",
    "print(\"predicted answer is:\",k)\n",
    "print(\"probability of certainity was: \",pred_results[0][val_max])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "544f8e23-2f81-487c-a30f-cdad6d0089c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'john travelled the bathroom last saturday. Sandra dropped the football in the garden.'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story=\"john travelled the bathroom last saturday. Sandra dropped the football in the garden.\"\n",
    "my_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a19b63c6-71e1-4331-8fd2-01fa1135ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question=\"did john travelled the bathroom last friday?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7415a5bf-499c-4fbd-883a-9df939247f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did', 'john', 'travelled', 'the', 'bathroom', 'last', 'friday?']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "31a3a646-d539-4ee9-bfeb-b641e0991edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=[(my_story,my_question,'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "37d3226d-0a66-42ce-8cbe-9cae1ad0ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans=vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "164e32ed-b560-4eeb-bba2-fa92b1a1d231",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_16_1/embedding_24_1/GatherV2 defined at (most recent call last):\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\runpy.py\", line 198, in _run_module_as_main\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\runpy.py\", line 88, in _run_code\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\asyncio\\events.py\", line 89, in _run\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 602, in run_cell\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_19184\\631816301.py\", line 2, in <module>\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 588, in predict\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 282, in one_step_on_data_distributed\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 125, in wrapper\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 271, in one_step_on_data\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 110, in predict_step\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 953, in __call__\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 183, in call\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 206, in _run_through_graph\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 647, in call\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 953, in __call__\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 166, in call\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 6275, in take\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2619, in take\n\nindices[0,0] = 38 is not in [0, 38)\n\t [[{{node functional_16_1/embedding_24_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_55971]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[205]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pred_results=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmy_story\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmy_ques\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Graph execution error:\n\nDetected at node functional_16_1/embedding_24_1/GatherV2 defined at (most recent call last):\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\runpy.py\", line 198, in _run_module_as_main\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\runpy.py\", line 88, in _run_code\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\asyncio\\events.py\", line 89, in _run\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 602, in run_cell\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_19184\\631816301.py\", line 2, in <module>\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 588, in predict\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 282, in one_step_on_data_distributed\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 125, in wrapper\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 271, in one_step_on_data\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 110, in predict_step\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 953, in __call__\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 183, in call\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 206, in _run_through_graph\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 647, in call\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 953, in __call__\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 166, in call\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 6275, in take\n\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2619, in take\n\nindices[0,0] = 38 is not in [0, 38)\n\t [[{{node functional_16_1/embedding_24_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_55971]"
     ]
    }
   ],
   "source": [
    "pred_results=model.predict(([my_story,my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "39558a9d-7f8a-4438-97c4-b763649f88d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max my_story: 38\n",
      "max my_ques: 38\n",
      "vocab_size: 38\n"
     ]
    }
   ],
   "source": [
    "print(\"max my_story:\", my_story.max())\n",
    "print(\"max my_ques:\", my_ques.max())\n",
    "print(\"vocab_size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7d3f3625-2d28-4eba-acb6-b3276de2cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "my_story = np.where(my_story >= vocab_size, 0, my_story)\n",
    "my_ques  = np.where(my_ques  >= vocab_size, 0, my_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fad1770f-6c58-46fa-83c1-b6964a2f5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = my_story.reshape(1, -1)\n",
    "my_ques  = my_ques.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "188eac6d-6a61-45a9-866f-1a800ce39b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_results = model.predict([my_story, my_ques])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042a770-c718-46ee-8adf-37685c2cb0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
